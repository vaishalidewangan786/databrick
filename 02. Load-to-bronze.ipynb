{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e535af55-852d-447c-88d1-e363e52fd23f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(name=\"env\",defaultValue='',label='Enter the environment in lower case')\n",
    "env = dbutils.widgets.get(\"env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b389a163-9fd4-4d60-89eb-1d8106a6fb94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"/Workspace/project 1/04. Common\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd070596-47c6-4082-9d8c-953c99232551",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    " Creating a read_Traffic_Data() Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34492334-dc4b-4248-8be7-5b610fc1b4b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def read_Traffic_Data():\n",
    "    from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "    from pyspark.sql.functions import current_timestamp\n",
    "    print(\"Reading the Raw Traffic Data :  \", end='')\n",
    "    schema = StructType([\n",
    "    StructField(\"Record_ID\",IntegerType()),\n",
    "    StructField(\"Count_point_id\",IntegerType()),\n",
    "    StructField(\"Direction_of_travel\",StringType()),\n",
    "    StructField(\"Year\",IntegerType()),\n",
    "    StructField(\"Count_date\",StringType()),\n",
    "    StructField(\"hour\",IntegerType()),\n",
    "    StructField(\"Region_id\",IntegerType()),\n",
    "    StructField(\"Region_name\",StringType()),\n",
    "    StructField(\"Local_authority_name\",StringType()),\n",
    "    StructField(\"Road_name\",StringType()),\n",
    "    StructField(\"Road_Category_ID\",IntegerType()),\n",
    "    StructField(\"Start_junction_road_name\",StringType()),\n",
    "    StructField(\"End_junction_road_name\",StringType()),\n",
    "    StructField(\"Latitude\",DoubleType()),\n",
    "    StructField(\"Longitude\",DoubleType()),\n",
    "    StructField(\"Link_length_km\",DoubleType()),\n",
    "    StructField(\"Pedal_cycles\",IntegerType()),\n",
    "    StructField(\"Two_wheeled_motor_vehicles\",IntegerType()),\n",
    "    StructField(\"Cars_and_taxis\",IntegerType()),\n",
    "    StructField(\"Buses_and_coaches\",IntegerType()),\n",
    "    StructField(\"LGV_Type\",IntegerType()),\n",
    "    StructField(\"HGV_Type\",IntegerType()),\n",
    "    StructField(\"EV_Car\",IntegerType()),\n",
    "    StructField(\"EV_Bike\",IntegerType())\n",
    "    ])\n",
    "\n",
    "    rawTraffic_stream = (spark.readStream\n",
    "        .format(\"cloudFiles\")\n",
    "        .option(\"cloudFiles.format\",\"csv\")\n",
    "        .option('cloudFiles.schemaLocation',f'{checkpoint}/rawTrafficLoad/schemaInfer')\n",
    "        .option('header','true')\n",
    "        .schema(schema)\n",
    "        .load(landing+'/raw_traffic/')\n",
    "        .withColumn(\"Extract_Time\", current_timestamp()))\n",
    "    \n",
    "    print('Reading Succcess !!')\n",
    "    print('*******************')\n",
    "    return rawTraffic_stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "901923e1-a27d-4470-84b8-d32f69c965ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "Creating read_Road_Data() Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04528c21-6549-4fff-81b4-44e375856f1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def read_Road_Data():\n",
    "    from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "    from pyspark.sql.functions import current_timestamp\n",
    "    print(\"Reading the Raw Roads Data :  \", end='')\n",
    "    schema = StructType([\n",
    "        StructField('Road_ID',IntegerType()),\n",
    "        StructField('Road_Category_Id',IntegerType()),\n",
    "        StructField('Road_Category',StringType()),\n",
    "        StructField('Region_ID',IntegerType()),\n",
    "        StructField('Region_Name',StringType()),\n",
    "        StructField('Total_Link_Length_Km',DoubleType()),\n",
    "        StructField('Total_Link_Length_Miles',DoubleType()),\n",
    "        StructField('All_Motor_Vehicles',DoubleType())\n",
    "        \n",
    "        ])\n",
    "\n",
    "    rawRoads_stream = (spark.readStream\n",
    "        .format(\"cloudFiles\")\n",
    "        .option(\"cloudFiles.format\",\"csv\")\n",
    "        .option('cloudFiles.schemaLocation',f'{checkpoint}/rawRoadsLoad/schemaInfer')\n",
    "        .option('header','true')\n",
    "        .schema(schema)\n",
    "        .load(landing+'/raw_roads/')\n",
    "        )\n",
    "    \n",
    "    print('Reading Succcess !!')\n",
    "    print('*******************')\n",
    "\n",
    "    return rawRoads_stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73111ecf-ca8d-4e97-9f4a-eca37d8b8645",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Creating write_Traffic_Data(StreamingDF,environment) Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91672696-f282-4a99-aec3-e9efe819e9a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def write_Traffic_Data(StreamingDF,environment):\n",
    "    print(f'Writing data to {environment} raw_traffic table', end='' )\n",
    "    write_Stream = (StreamingDF.writeStream\n",
    "                    .format('delta')\n",
    "                    .option(\"checkpointLocation\",checkpoint + '/rawTrafficLoad/Checkpt')\n",
    "                    .outputMode('append')\n",
    "                    .queryName('rawTrafficWriteStream')\n",
    "                    .trigger(availableNow=True)\n",
    "                    .toTable(f\"`{environment}`.`bronze`.`raw_traffic`\"))\n",
    "    \n",
    "    write_Stream.awaitTermination()\n",
    "    print('Write Success')\n",
    "    print(\"****************************\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49973216-f3a4-493f-aebd-c52a291379c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Creating write_Road_Data(StreamingDF,environment) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39f81ace-a0ca-483b-ac11-dd7c7b5ab281",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def write_Road_Data(StreamingDF,environment):\n",
    "    print(f'Writing data to {environment} raw_roads table', end='' )\n",
    "    write_Data = (StreamingDF.writeStream\n",
    "                    .format('delta')\n",
    "                    .option(\"checkpointLocation\",checkpoint + '/rawRoadsLoad/Checkpt')\n",
    "                    .outputMode('append')\n",
    "                    .queryName('rawRoadsWriteStream')\n",
    "                    .trigger(availableNow=True)\n",
    "                    .toTable(f\"`{environment}`.`bronze`.`raw_roads`\"))\n",
    "    \n",
    "    write_Data.awaitTermination()\n",
    "    print('Write Success')\n",
    "    print(\"****************************\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63f47eda-0059-4486-ac29-be8397a69e2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Reading the raw_traffic's data from landing to Bronze\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c482dd14-caa1-4c2d-af59-6ca3330710c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "read_Df = read_Traffic_Data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b43fe0f0-1252-49ef-a143-822d2b6af7f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Reading the raw_roads's data from landing to Bronze\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "834d948d-1b53-4b97-a370-12baf2b4153f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "read_roads = read_Road_Data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62ab1dec-1502-46e4-8706-a025848078cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "Writing the raw_traffic's data from landing to Bronze\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e14281b8-84a8-454d-a5f7-ce6eeaded064",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "write_Traffic_Data(read_Df,env)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ba3b902-844b-4f55-826f-d7f16aa17d59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "Writing the raw_roads's data from landing to Bronze\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55199672-7c9e-451b-9327-df83411993d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "write_Road_Data(read_roads,env)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02. Load-to-bronze",
   "widgets": {
    "env": {
     "currentValue": "dev",
     "nuid": "6867d967-e108-46da-801f-9e9ccfc0a2ed",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Enter the environment in lower case",
      "name": "env",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Enter the environment in lower case",
      "name": "env",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
