# End-to-End Traffic Data Pipeline using Databricks Unity Catalog 
![Azure](https://img.shields.io/badge/Azure-Cloud-blue)  
![Databricks](https://img.shields.io/badge/Databricks-Automation-orange)  
![CI/CD](https://img.shields.io/badge/CI%2FCD-GitHub%20Actions-brightgreen)  

## 📑 Project Description  
This project implements an end-to-end data pipeline using **Databricks Unity Catalog** to process traffic and road data stored in **Azure Data Lake Storage**. It leverages **Databricks Autoloader** for real-time ingestion, CI/CD via **GitHub Actions**, and automation using **Databricks Workflows**. A **Power BI dashboard** visualizes key insights for traffic analysis.  

## 🛠️ Tech Stack  
- Databricks (Unity Catalog, Workflow)
- Azure Data Lake Storage  
- GitHub Actions (CI/CD)  
- Power BI  


## 🗺️ Architecture  
![Architecture Diagram](https://github.com/user-attachments/assets/4927e3eb-b5ba-427d-a43f-f058869e8445)

## 🚀 Features  
- Automated data ingestion with Databricks Autoloader  
- Three-layer data architecture (Bronze, Silver, Gold)  
- Unity Catalog for data governance  
- CI/CD with GitHub Actions  
- Automated pipeline triggers via Databricks Automation  
- Interactive Power BI dashboard for traffic insights  

## 🗃️ Project Structure  
├── data/  
├── notebooks/  
├── scripts/  
├── dashboards/  
├── workflows/  
└── README.md  

## 📊 Results  
![Power BI Dashboard](https://github.com/user-attachments/assets/10fe7d5c-655c-4417-9517-c9e9486b1f8c)

## 🎥 Project Demo  
Here’s a quick demo of the end-to-end traffic data pipeline using **Databricks Unity Catalog**:  

#Azure Set-Up
[A]()




## 💡 Contact  
- **Name:** Vaishali  
- **LinkedIn:** [LinkedIn Profile](https://www.linkedin.com/in/vaishali-dewangan-2060721a5/)  
- **Email:** vaishalidewangan82768@gmail.com  






